[da]
# The address of the Celestia RPC server to interact with.
rpc_url = "ws://127.0.0.1:26658"
grpc_url = "http://127.0.0.1:9091"
grpc_auth_token = "MY.SECRET.TOKEN"

# The private key in hex format of Celestia wallet that has enough TIA to publish blobs.
signer_private_key = "aec34bb1cfae6e906594dc106af4057a9046f769e2eeed67d040f0107e15e167"


[storage]
# The path to the rollup's data directory. Paths that do not begin with `/` are interpreted as relative paths.
path = "./rollup-state/rollup-starter-data-celestia"

user_commit_concurrency = 6
kernel_commit_concurrency = 2
# Disable pruning for now
# pruner_block_interval = 100_000
pruner_versions_to_keep = 100
#state_cache_size = 10000000000 # 10GB
state_cache_size = 4294967296
# The number of 4kb buckets to allocate for the state DB
# The state DB will not exceed this size, and you'll get a warning when it fills up to 90% capacity.
# user_hashtable_buckets = 64_000_000 # 256 GB. You will need much more for production deployments
user_hashtable_buckets = 1_000_000
# This paramater introduces performance penalty and should be changed in production.
# It allows avoiding allocating 256GB at the start
user_preallocate_ht = false

# We define the rollup's genesis to occur at block number `start_height`. The rollup will ignore
# any blocks before this height
[runner]
da_polling_interval_ms = 2_000
concurrent_sync_tasks = 2
pre_fetched_blocks_capacity = 10

[runner.http_config]
bind_host = "0.0.0.0"
bind_port = 12346
public_address = "http://127.0.0.1:12346"

[monitoring]
telegraf_address = "127.0.0.1:8094"
# Defines how many measurements a rollup node will accumulate before sending it to the Telegraf.
# It is expected from the rollup node to produce metrics all the time,
# so measurements are buffered by size and not sent by time.
# and below 67 KB, which is the maximal UDP packet size.
# It also means that if a single serialized metric is larger than this value, a UDP packet will be larger.
# The default value is 508.
# max_datagram_size = 508
# How many metrics are allowed to be in pending state, before new metrics will be dropped.
# This is a number of metrics, not serialized bytes.
# The total number of bytes to be held in memory might vary per metric + `max_datagram_size`
# max_pending_metrics = 100


[proof_manager]
aggregated_proof_block_jump = 1
prover_address = "0xA6edfca3AA985Dd3CC728BFFB700933a986aC085"
max_number_of_transitions_in_db = 100
max_number_of_transitions_in_memory = 20


[sequencer]
max_batch_size_bytes = 2048576
max_concurrent_blobs = 128
max_allowed_node_distance_behind = 10
rollup_address = "0xA6edfca3AA985Dd3CC728BFFB700933a986aC085"
blob_processing_timeout_secs = 60

[sequencer.preferred]
disable_state_root_consistency_checks = true
# Strategy for handling recovery scenarios when the sequencer is too far behind.
# "None" - Shutdown the sequencer instead of attempting recovery (default)
# "TryToSave" - Attempt to recover by flushing batches and catching up with the chain
recovery_strategy = "TryToSave"
batch_execution_time_limit_millis = 6000
# If you have one available, uncomment the line below to use a postgres database for the sequencer's soft confirmations. This gives much better performance and durability.
# postgres_connection_string="postgres://postgres:sequencerdb@localhost:5432/rollup" 
ideal_lag_behind_finalized_slot = 1
# The sequencer optimistically pre-executes transactions across multiple worker threads.
# This warms up caches so the main transaction executor can run with ready-to-use data.
# This variable determines the number of worker threads.
num_cache_warmup_workers = 0
is_replica = false

[sequencer.preferred.timing_oracle]
priority_fee_percentage = 0
max_fee = 100_000_000
interval_millis = 50

[sequencer.extension]
max_log_limit = 20000
